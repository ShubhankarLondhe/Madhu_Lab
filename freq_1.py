import numpy as np
import matplotlib.pyplot as plt



def plot(predict, test_data):		#, train_data

	cg = list(range(1,17))

	pred = [i/1e6 for i in predict]
	test = [i/1e6 for i in test_data]
	
	print(sum(pred))
	plt.plot(cg, pred, 'b-', label='Prediction')
	plt.xlabel("Chemical Group Number")
	plt.ylabel("Frequency ($10^6$)")
	plt.title("Frequency of central chemical groups in NRaa database")
	plt.xticks(cg)

	print(sum(test))
	plt.plot(cg, test, 'r-', label='Test Dataset')
	plt.xlabel("Chemical Group Number")
	plt.ylabel("Frequency ($10^6$)")
	plt.title("Frequency of central chemical groups in NRaa database")
	plt.xticks(cg)

	# train = [i/(1e6) for i in train_data] 
	# print(sum(train))
	# plt.plot(cg, train, 'g-', label='Normalized Train Dataset')
	# plt.xlabel("Chemical Group Number")
	# plt.ylabel("Frequency ($10^6$)")
	# plt.title("Frequency of central chemical groups in NRaa database")
	# plt.xticks(cg)


	plt.legend()
	plt.show()


def add(a,b,c,d):
	s = []
	for i in range(len(a)):
		s.append(a[i]+b[i]+c[i]+d[i])
	return s

# Train 1

ls1 = [
3.616400000000000000e+04,
1.896399000000000000e+06,
1.181320000000000000e+05,
5.280600000000000000e+04,
2.051540000000000000e+05,
1.422578000000000000e+06,
4.681200000000000000e+04,
9.282400000000000000e+04,
1.405740000000000000e+05,
5.106650000000000000e+05,
2.071693000000000000e+06,
3.767900000000000000e+04,
4.283610000000000000e+05,
1.762720000000000000e+05,
1.871343000000000000e+06,
7.254400000000000000e+04
]

lt1 = [
2.860756000000000000e+06,
2.145601000000000000e+06,
1.479000000000000000e+05,
6.518500000000000000e+04,
1.605610000000000000e+05,
3.561570000000000000e+05,
3.391070000000000000e+05,
1.711151000000000000e+06,
2.356580000000000000e+05,
3.923700000000000000e+04,
1.307340000000000000e+05,
6.688530000000000000e+05,
5.442600000000000000e+04,
1.189340000000000000e+05,
3.951400000000000000e+04,
1.029740000000000000e+05
]

# Train 2

ls2 = [
2.276360000000000000e+05,
2.739025000000000000e+06,
7.424000000000000000e+04,
1.477010000000000000e+05,
1.109960000000000000e+05,
7.660800000000000000e+04,
3.099200000000000000e+04,
9.221100000000000000e+04,
1.058660000000000000e+05,
3.028070000000000000e+05,
1.857213000000000000e+06,
1.971700000000000000e+04,
1.885920000000000000e+05,
8.392200000000000000e+04,
2.993831000000000000e+06,
1.286430000000000000e+05
]

lt2 = [
2.863143000000000000e+06,
2.147539000000000000e+06,
1.488600000000000000e+05,
6.542000000000000000e+04,
1.600950000000000000e+05,
3.558870000000000000e+05,
3.397440000000000000e+05,
1.709709000000000000e+06,
2.345620000000000000e+05,
3.893900000000000000e+04,
1.304290000000000000e+05,
6.684560000000000000e+05,
5.404000000000000000e+04,
1.193310000000000000e+05,
3.950200000000000000e+04,
1.031340000000000000e+05
]


# # Train 3

ls3 = [
1.077420000000000000e+05,
1.448900000000000000e+05,
8.591300000000000000e+04,
4.263000000000000000e+04,
7.819200000000000000e+04,
1.505910000000000000e+05,
2.393500000000000000e+05,
5.183870000000000000e+05,
1.552470000000000000e+05,
3.993010000000000000e+05,
1.537214000000000000e+06,
3.112500000000000000e+05,
2.312760000000000000e+05,
1.801390000000000000e+05,
4.919499000000000000e+06,
7.837900000000000000e+04
]

lt3 = [
2.860944000000000000e+06,
2.147705000000000000e+06,
1.481870000000000000e+05,
6.570500000000000000e+04,
1.596630000000000000e+05,
3.569660000000000000e+05,
3.381000000000000000e+05,
1.711478000000000000e+06,
2.350960000000000000e+05,
3.927400000000000000e+04,
1.304660000000000000e+05,
6.686210000000000000e+05,
5.413900000000000000e+04,
1.191070000000000000e+05,
3.963300000000000000e+04,
1.032820000000000000e+05
]


# # Train 4

ls4 = [
1.639860000000000000e+05,
1.134030000000000000e+05,
1.536210000000000000e+05,
9.839500000000000000e+04,
1.410630000000000000e+05,
1.576790000000000000e+05,
1.222940000000000000e+05,
1.084859000000000000e+06,
1.527110000000000000e+05,
7.342810000000000000e+05,
1.303990000000000000e+05,
3.815600000000000000e+04,
3.628620000000000000e+05,
1.120310000000000000e+05,
5.301042000000000000e+06,
3.132180000000000000e+05
]

lt4 = [
2.861746000000000000e+06,
2.149423000000000000e+06,
1.479960000000000000e+05,
6.596200000000000000e+04,
1.600430000000000000e+05,
3.559690000000000000e+05,
3.390140000000000000e+05,
1.711661000000000000e+06,
2.351570000000000000e+05,
3.882200000000000000e+04,
1.309600000000000000e+05,
6.685250000000000000e+05,
5.433600000000000000e+04,
1.184160000000000000e+05,
3.913700000000000000e+04,
1.024920000000000000e+05
]


# # Train 5

ls5 = [
5.207500000000000000e+04,
2.471612000000000000e+06,
6.351520000000000000e+05,
2.274800000000000000e+05,
3.031510000000000000e+05,
8.828500000000000000e+04,
2.778680000000000000e+05,
7.641810000000000000e+05,
1.828020000000000000e+05,
7.095670000000000000e+05,
3.410790000000000000e+05,
1.801830000000000000e+05,
1.972160000000000000e+05,
2.281790000000000000e+05,
2.203939000000000000e+06,
3.172310000000000000e+05
]

lt5 = [
2.861001000000000000e+06,
2.146807000000000000e+06,
1.485930000000000000e+05,
6.554700000000000000e+04,
1.599140000000000000e+05,
3.558060000000000000e+05,
3.390530000000000000e+05,
1.710814000000000000e+06,
2.353750000000000000e+05,
3.925200000000000000e+04,
1.309740000000000000e+05,
6.694950000000000000e+05,
5.387500000000000000e+04,
1.189850000000000000e+05,
3.944300000000000000e+04,
1.029380000000000000e+05
]


# plot(ls1,lt1,add(lt2,lt3,lt4,lt5))
# plot(ls2,lt2,add(lt1,lt3,lt4,lt5))
# plot(ls3,lt3,add(lt2,lt1,lt4,lt5))
# plot(ls4,lt4,add(lt2,lt3,lt1,lt5))
# plot(ls5,lt5,add(lt2,lt3,lt4,lt1))

# SELU Activation function:
pred_selu = [9177000,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]  # for all datasets: Normal, Relpos, Relpos_Norm


plot(pred_selu, lt1)